{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant Disease Detection 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WRXBfHJsGIa",
        "outputId": "0d6e5749-27c3-40a4-eacb-ecf015f52112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z80-QQNDsGMk",
        "colab": {}
      },
      "source": [
        "# Import resources\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vR3IFWajFUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EtzRpna1sGQz",
        "outputId": "5a7b10ab-02d1-45f1-8aba-7d76c5428519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check if GPU/TPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('Training on CPU ...')\n",
        "else:\n",
        "    print('Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "baC8RfyxsGXY",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDQQeI0VsGch",
        "outputId": "0e9c7d2a-f9cc-4de8-bee3-2c31fab5288e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_dir = 'gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "shutil.copy('gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease/fn_to_dn.json','fn_to_dn.json')\n",
        "shutil.copy('gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease/test.jpg','test.jpg')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E6eJ9w9YsGi8",
        "colab": {}
      },
      "source": [
        "# Define your transforms for the training and testing sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'valid']}\n",
        "\n",
        "# Using the image datasets and the trainforms, define the dataloaders\n",
        "batch_size = 64\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'valid']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HBHkLjlYsGob",
        "colab": {}
      },
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kk4MJbese6B",
        "outputId": "b1cadca8-5351-4747-ebee-5138dfc2251e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(dataset_sizes)\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 946, 'valid': 17}\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Ci0fE8Tse9F",
        "colab": {}
      },
      "source": [
        "# Label mapping\n",
        "with open('fn_to_dn.json', 'r') as f:\n",
        "    fn_to_dn= json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "roAFvxS1sfAU",
        "outputId": "472015fa-d0f8-46f1-fbb2-1e0611fc522a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Run this to test the data loader\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "images.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LnxoYvW0sfGG",
        "outputId": "e7f73599-3e9e-4df9-b714-c185acb86324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# # Run this to test your data loader\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "rand_idx = np.random.randint(len(images))\n",
        "print(rand_idx)\n",
        "print(\"label: {}, class: {}, name: {}\".format(labels[rand_idx].item(),\n",
        "                                               class_names[labels[rand_idx].item()],\n",
        "                                               fn_to_dn[class_names[labels[rand_idx].item()]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "label: 2, class: 11, name: Healthy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bLHN-uunsfMM",
        "outputId": "56a89d8c-0ae0-4ff9-9f8a-d5aa477e8e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12063
        }
      },
      "source": [
        "model_name = 'densenet' \n",
        "#model_name = 'vgg' \n",
        "#model_name = 'gnet' \n",
        "# model_name = 'resnet'\n",
        "nif=2208\n",
        "\n",
        "if model_name == 'densenet':\n",
        "    model = models.densenet161(pretrained=True)\n",
        "    num_in_features = nif\n",
        "    print(model)\n",
        "elif model_name == 'vgg':\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    num_in_features = nif\n",
        "    print(model.classifier)\n",
        "elif model_name == 'gnet':\n",
        "    model = models.googlenet(pretrained=True)\n",
        "    num_in_features = nif\n",
        "    print(model)\n",
        "elif model_name == 'resnet':\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_in_features = nif\n",
        "    print(model)\n",
        "else:\n",
        "    print(\"Unknown model, please choose 'densenet' or 'vgg' or 'Google Net'\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/checkpoints/densenet161-8d451a50.pth\n",
            "100%|██████████| 115730790/115730790 [00:07<00:00, 16428543.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer25): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer26): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer27): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer28): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer29): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer30): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer31): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer32): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer33): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer34): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer35): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer36): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xxpu-O3bsfQJ",
        "colab": {}
      },
      "source": [
        "# Create classifier\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "def build_classifier(num_in_features, hidden_layers, num_out_features):\n",
        "   \n",
        "    classifier = nn.Sequential()\n",
        "    if hidden_layers == None:\n",
        "        classifier.add_module('fc0', nn.Linear(num_in_features, 102))\n",
        "    else:\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        classifier.add_module('fc0', nn.Linear(num_in_features, hidden_layers[0]))\n",
        "        classifier.add_module('relu0', nn.ReLU())\n",
        "        classifier.add_module('drop0', nn.Dropout(.6))\n",
        "        classifier.add_module('relu1', nn.ReLU())\n",
        "        classifier.add_module('drop1', nn.Dropout(.5))\n",
        "        for i, (h1, h2) in enumerate(layer_sizes):\n",
        "            classifier.add_module('fc'+str(i+1), nn.Linear(h1, h2))\n",
        "            classifier.add_module('relu'+str(i+1), nn.ReLU())\n",
        "            classifier.add_module('drop'+str(i+1), nn.Dropout(.5))\n",
        "        classifier.add_module('output', nn.Linear(hidden_layers[-1], num_out_features))\n",
        "        \n",
        "    return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uJhshsnMsfJX",
        "outputId": "93f346f2-58c9-44d2-b5aa-38c724346f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "hidden_layers = None#[4096, 1024, 256][512, 256, 128]\n",
        "\n",
        "classifier = build_classifier(num_in_features, hidden_layers, 102)\n",
        "print(classifier)\n",
        "\n",
        " # Only train the classifier parameters, feature parameters are frozen\n",
        "if model_name == 'densenet':\n",
        "    model.classifier = classifier\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adadelta(model.parameters()) # Adadelta #weight optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    #optimizer_conv = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.001, momentum=0.9)\n",
        "    sched = optim.lr_scheduler.StepLR(optimizer, step_size=4)\n",
        "elif model_name == 'vgg':\n",
        "    model.classifier = classifier\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n",
        "    sched = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (fc0): Linear(in_features=2208, out_features=102, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "193_EfcLsfDz",
        "colab": {}
      },
      "source": [
        "# Adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "def train_model(model, criterion, optimizer, sched, num_epochs=5):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        #sched.step()\n",
        "                        loss.backward()\n",
        "                        \n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    #load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkgn4OlRjleP",
        "outputId": "08de1ef5-379c-4a65-97f9-384efd934413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 31391
        }
      },
      "source": [
        "epochs = 500\n",
        "model.to(device)\n",
        "model = train_model(model, criterion, optimizer, sched, epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "----------\n",
            "train Loss: 2.5707 Acc: 0.1850\n",
            "valid Loss: 5.7757 Acc: 0.0588\n",
            "\n",
            "Epoch 2/500\n",
            "----------\n",
            "train Loss: 1.7433 Acc: 0.4091\n",
            "valid Loss: 6.5853 Acc: 0.0588\n",
            "\n",
            "Epoch 3/500\n",
            "----------\n",
            "train Loss: 1.3795 Acc: 0.5328\n",
            "valid Loss: 6.6570 Acc: 0.0588\n",
            "\n",
            "Epoch 4/500\n",
            "----------\n",
            "train Loss: 1.1764 Acc: 0.6258\n",
            "valid Loss: 6.8642 Acc: 0.1176\n",
            "\n",
            "Epoch 5/500\n",
            "----------\n",
            "train Loss: 1.1689 Acc: 0.6036\n",
            "valid Loss: 7.2286 Acc: 0.0000\n",
            "\n",
            "Epoch 6/500\n",
            "----------\n",
            "train Loss: 1.0048 Acc: 0.6691\n",
            "valid Loss: 7.4102 Acc: 0.0588\n",
            "\n",
            "Epoch 7/500\n",
            "----------\n",
            "train Loss: 1.0775 Acc: 0.6416\n",
            "valid Loss: 7.5293 Acc: 0.0588\n",
            "\n",
            "Epoch 8/500\n",
            "----------\n",
            "train Loss: 0.9272 Acc: 0.6913\n",
            "valid Loss: 7.7489 Acc: 0.0588\n",
            "\n",
            "Epoch 9/500\n",
            "----------\n",
            "train Loss: 0.8894 Acc: 0.7114\n",
            "valid Loss: 7.9409 Acc: 0.1176\n",
            "\n",
            "Epoch 10/500\n",
            "----------\n",
            "train Loss: 0.8394 Acc: 0.7262\n",
            "valid Loss: 8.2438 Acc: 0.0588\n",
            "\n",
            "Epoch 11/500\n",
            "----------\n",
            "train Loss: 0.8573 Acc: 0.7051\n",
            "valid Loss: 8.3292 Acc: 0.0588\n",
            "\n",
            "Epoch 12/500\n",
            "----------\n",
            "train Loss: 0.7788 Acc: 0.7262\n",
            "valid Loss: 8.1678 Acc: 0.1176\n",
            "\n",
            "Epoch 13/500\n",
            "----------\n",
            "train Loss: 0.8205 Acc: 0.7061\n",
            "valid Loss: 8.4979 Acc: 0.0588\n",
            "\n",
            "Epoch 14/500\n",
            "----------\n",
            "train Loss: 0.7843 Acc: 0.7294\n",
            "valid Loss: 8.6813 Acc: 0.0588\n",
            "\n",
            "Epoch 15/500\n",
            "----------\n",
            "train Loss: 0.7806 Acc: 0.7336\n",
            "valid Loss: 9.0305 Acc: 0.1176\n",
            "\n",
            "Epoch 16/500\n",
            "----------\n",
            "train Loss: 0.8090 Acc: 0.7178\n",
            "valid Loss: 8.6998 Acc: 0.0000\n",
            "\n",
            "Epoch 17/500\n",
            "----------\n",
            "train Loss: 0.7356 Acc: 0.7452\n",
            "valid Loss: 8.7309 Acc: 0.1176\n",
            "\n",
            "Epoch 18/500\n",
            "----------\n",
            "train Loss: 0.6986 Acc: 0.7643\n",
            "valid Loss: 8.8546 Acc: 0.1176\n",
            "\n",
            "Epoch 19/500\n",
            "----------\n",
            "train Loss: 0.7128 Acc: 0.7611\n",
            "valid Loss: 9.0532 Acc: 0.0588\n",
            "\n",
            "Epoch 20/500\n",
            "----------\n",
            "train Loss: 0.7371 Acc: 0.7431\n",
            "valid Loss: 9.2469 Acc: 0.0588\n",
            "\n",
            "Epoch 21/500\n",
            "----------\n",
            "train Loss: 0.7006 Acc: 0.7516\n",
            "valid Loss: 9.3808 Acc: 0.0588\n",
            "\n",
            "Epoch 22/500\n",
            "----------\n",
            "train Loss: 0.6263 Acc: 0.7886\n",
            "valid Loss: 9.1276 Acc: 0.0588\n",
            "\n",
            "Epoch 23/500\n",
            "----------\n",
            "train Loss: 0.6270 Acc: 0.7717\n",
            "valid Loss: 9.7110 Acc: 0.0588\n",
            "\n",
            "Epoch 24/500\n",
            "----------\n",
            "train Loss: 0.5846 Acc: 0.7939\n",
            "valid Loss: 9.5716 Acc: 0.0000\n",
            "\n",
            "Epoch 25/500\n",
            "----------\n",
            "train Loss: 0.6904 Acc: 0.7463\n",
            "valid Loss: 9.8493 Acc: 0.0588\n",
            "\n",
            "Epoch 26/500\n",
            "----------\n",
            "train Loss: 0.6104 Acc: 0.7865\n",
            "valid Loss: 9.3374 Acc: 0.1765\n",
            "\n",
            "Epoch 27/500\n",
            "----------\n",
            "train Loss: 0.6166 Acc: 0.7928\n",
            "valid Loss: 9.5899 Acc: 0.1176\n",
            "\n",
            "Epoch 28/500\n",
            "----------\n",
            "train Loss: 0.6530 Acc: 0.7674\n",
            "valid Loss: 9.8700 Acc: 0.0000\n",
            "\n",
            "Epoch 29/500\n",
            "----------\n",
            "train Loss: 0.6176 Acc: 0.7801\n",
            "valid Loss: 9.9385 Acc: 0.0000\n",
            "\n",
            "Epoch 30/500\n",
            "----------\n",
            "train Loss: 0.5515 Acc: 0.7992\n",
            "valid Loss: 9.8793 Acc: 0.1176\n",
            "\n",
            "Epoch 31/500\n",
            "----------\n",
            "train Loss: 0.6301 Acc: 0.7696\n",
            "valid Loss: 9.9550 Acc: 0.1176\n",
            "\n",
            "Epoch 32/500\n",
            "----------\n",
            "train Loss: 0.5947 Acc: 0.7854\n",
            "valid Loss: 10.2448 Acc: 0.0588\n",
            "\n",
            "Epoch 33/500\n",
            "----------\n",
            "train Loss: 0.5941 Acc: 0.7886\n",
            "valid Loss: 10.0614 Acc: 0.0588\n",
            "\n",
            "Epoch 34/500\n",
            "----------\n",
            "train Loss: 0.5500 Acc: 0.8066\n",
            "valid Loss: 10.2235 Acc: 0.0588\n",
            "\n",
            "Epoch 35/500\n",
            "----------\n",
            "train Loss: 0.6164 Acc: 0.7717\n",
            "valid Loss: 10.5533 Acc: 0.0588\n",
            "\n",
            "Epoch 36/500\n",
            "----------\n",
            "train Loss: 0.5447 Acc: 0.8044\n",
            "valid Loss: 10.2256 Acc: 0.1176\n",
            "\n",
            "Epoch 37/500\n",
            "----------\n",
            "train Loss: 0.5464 Acc: 0.8034\n",
            "valid Loss: 10.4348 Acc: 0.0000\n",
            "\n",
            "Epoch 38/500\n",
            "----------\n",
            "train Loss: 0.6566 Acc: 0.7748\n",
            "valid Loss: 10.7244 Acc: 0.0588\n",
            "\n",
            "Epoch 39/500\n",
            "----------\n",
            "train Loss: 0.5231 Acc: 0.8171\n",
            "valid Loss: 10.5474 Acc: 0.0588\n",
            "\n",
            "Epoch 40/500\n",
            "----------\n",
            "train Loss: 0.4872 Acc: 0.8351\n",
            "valid Loss: 10.7442 Acc: 0.0588\n",
            "\n",
            "Epoch 41/500\n",
            "----------\n",
            "train Loss: 0.5816 Acc: 0.8002\n",
            "valid Loss: 11.1580 Acc: 0.1176\n",
            "\n",
            "Epoch 42/500\n",
            "----------\n",
            "train Loss: 0.4968 Acc: 0.8266\n",
            "valid Loss: 10.5911 Acc: 0.0588\n",
            "\n",
            "Epoch 43/500\n",
            "----------\n",
            "train Loss: 0.5604 Acc: 0.7896\n",
            "valid Loss: 11.1477 Acc: 0.0588\n",
            "\n",
            "Epoch 44/500\n",
            "----------\n",
            "train Loss: 0.5251 Acc: 0.8161\n",
            "valid Loss: 10.5209 Acc: 0.0588\n",
            "\n",
            "Epoch 45/500\n",
            "----------\n",
            "train Loss: 0.5200 Acc: 0.8161\n",
            "valid Loss: 10.5853 Acc: 0.0588\n",
            "\n",
            "Epoch 46/500\n",
            "----------\n",
            "train Loss: 0.5013 Acc: 0.8235\n",
            "valid Loss: 10.9224 Acc: 0.0588\n",
            "\n",
            "Epoch 47/500\n",
            "----------\n",
            "train Loss: 0.5757 Acc: 0.7875\n",
            "valid Loss: 10.3535 Acc: 0.0000\n",
            "\n",
            "Epoch 48/500\n",
            "----------\n",
            "train Loss: 0.5591 Acc: 0.7992\n",
            "valid Loss: 10.7847 Acc: 0.0588\n",
            "\n",
            "Epoch 49/500\n",
            "----------\n",
            "train Loss: 0.5376 Acc: 0.7970\n",
            "valid Loss: 10.7908 Acc: 0.1176\n",
            "\n",
            "Epoch 50/500\n",
            "----------\n",
            "train Loss: 0.5614 Acc: 0.7939\n",
            "valid Loss: 10.8583 Acc: 0.0588\n",
            "\n",
            "Epoch 51/500\n",
            "----------\n",
            "train Loss: 0.5489 Acc: 0.8097\n",
            "valid Loss: 10.7948 Acc: 0.0588\n",
            "\n",
            "Epoch 52/500\n",
            "----------\n",
            "train Loss: 0.4756 Acc: 0.8362\n",
            "valid Loss: 10.8088 Acc: 0.1176\n",
            "\n",
            "Epoch 53/500\n",
            "----------\n",
            "train Loss: 0.5242 Acc: 0.8224\n",
            "valid Loss: 10.6769 Acc: 0.1176\n",
            "\n",
            "Epoch 54/500\n",
            "----------\n",
            "train Loss: 0.5208 Acc: 0.8182\n",
            "valid Loss: 11.1375 Acc: 0.0588\n",
            "\n",
            "Epoch 55/500\n",
            "----------\n",
            "train Loss: 0.4067 Acc: 0.8584\n",
            "valid Loss: 10.8433 Acc: 0.0588\n",
            "\n",
            "Epoch 56/500\n",
            "----------\n",
            "train Loss: 0.5212 Acc: 0.8235\n",
            "valid Loss: 11.1254 Acc: 0.0588\n",
            "\n",
            "Epoch 57/500\n",
            "----------\n",
            "train Loss: 0.4903 Acc: 0.8171\n",
            "valid Loss: 10.9668 Acc: 0.0000\n",
            "\n",
            "Epoch 58/500\n",
            "----------\n",
            "train Loss: 0.4799 Acc: 0.8288\n",
            "valid Loss: 11.3137 Acc: 0.0588\n",
            "\n",
            "Epoch 59/500\n",
            "----------\n",
            "train Loss: 0.4920 Acc: 0.8182\n",
            "valid Loss: 11.4975 Acc: 0.1176\n",
            "\n",
            "Epoch 60/500\n",
            "----------\n",
            "train Loss: 0.4590 Acc: 0.8457\n",
            "valid Loss: 11.2013 Acc: 0.0588\n",
            "\n",
            "Epoch 61/500\n",
            "----------\n",
            "train Loss: 0.4707 Acc: 0.8372\n",
            "valid Loss: 11.2274 Acc: 0.0000\n",
            "\n",
            "Epoch 62/500\n",
            "----------\n",
            "train Loss: 0.5109 Acc: 0.8192\n",
            "valid Loss: 11.1492 Acc: 0.0588\n",
            "\n",
            "Epoch 63/500\n",
            "----------\n",
            "train Loss: 0.4731 Acc: 0.8224\n",
            "valid Loss: 11.4181 Acc: 0.0588\n",
            "\n",
            "Epoch 64/500\n",
            "----------\n",
            "train Loss: 0.4911 Acc: 0.8309\n",
            "valid Loss: 11.1902 Acc: 0.0588\n",
            "\n",
            "Epoch 65/500\n",
            "----------\n",
            "train Loss: 0.4636 Acc: 0.8372\n",
            "valid Loss: 11.4715 Acc: 0.0000\n",
            "\n",
            "Epoch 66/500\n",
            "----------\n",
            "train Loss: 0.5684 Acc: 0.7886\n",
            "valid Loss: 11.3362 Acc: 0.1176\n",
            "\n",
            "Epoch 67/500\n",
            "----------\n",
            "train Loss: 0.4649 Acc: 0.8404\n",
            "valid Loss: 11.6653 Acc: 0.0588\n",
            "\n",
            "Epoch 68/500\n",
            "----------\n",
            "train Loss: 0.4955 Acc: 0.8319\n",
            "valid Loss: 11.3540 Acc: 0.0588\n",
            "\n",
            "Epoch 69/500\n",
            "----------\n",
            "train Loss: 0.5104 Acc: 0.8203\n",
            "valid Loss: 11.5360 Acc: 0.0588\n",
            "\n",
            "Epoch 70/500\n",
            "----------\n",
            "train Loss: 0.5170 Acc: 0.8266\n",
            "valid Loss: 11.4047 Acc: 0.0588\n",
            "\n",
            "Epoch 71/500\n",
            "----------\n",
            "train Loss: 0.5336 Acc: 0.8224\n",
            "valid Loss: 11.5867 Acc: 0.0588\n",
            "\n",
            "Epoch 72/500\n",
            "----------\n",
            "train Loss: 0.4158 Acc: 0.8467\n",
            "valid Loss: 11.4790 Acc: 0.0588\n",
            "\n",
            "Epoch 73/500\n",
            "----------\n",
            "train Loss: 0.4595 Acc: 0.8362\n",
            "valid Loss: 11.4146 Acc: 0.0000\n",
            "\n",
            "Epoch 74/500\n",
            "----------\n",
            "train Loss: 0.4145 Acc: 0.8488\n",
            "valid Loss: 11.5181 Acc: 0.0588\n",
            "\n",
            "Epoch 75/500\n",
            "----------\n",
            "train Loss: 0.4261 Acc: 0.8446\n",
            "valid Loss: 11.5716 Acc: 0.0588\n",
            "\n",
            "Epoch 76/500\n",
            "----------\n",
            "train Loss: 0.4579 Acc: 0.8404\n",
            "valid Loss: 11.4170 Acc: 0.0588\n",
            "\n",
            "Epoch 77/500\n",
            "----------\n",
            "train Loss: 0.4922 Acc: 0.8256\n",
            "valid Loss: 11.5763 Acc: 0.0588\n",
            "\n",
            "Epoch 78/500\n",
            "----------\n",
            "train Loss: 0.4140 Acc: 0.8584\n",
            "valid Loss: 11.8927 Acc: 0.0588\n",
            "\n",
            "Epoch 79/500\n",
            "----------\n",
            "train Loss: 0.4909 Acc: 0.8277\n",
            "valid Loss: 11.6739 Acc: 0.0000\n",
            "\n",
            "Epoch 80/500\n",
            "----------\n",
            "train Loss: 0.4789 Acc: 0.8245\n",
            "valid Loss: 11.7052 Acc: 0.0588\n",
            "\n",
            "Epoch 81/500\n",
            "----------\n",
            "train Loss: 0.3832 Acc: 0.8605\n",
            "valid Loss: 12.0330 Acc: 0.0588\n",
            "\n",
            "Epoch 82/500\n",
            "----------\n",
            "train Loss: 0.4482 Acc: 0.8383\n",
            "valid Loss: 11.9547 Acc: 0.0588\n",
            "\n",
            "Epoch 83/500\n",
            "----------\n",
            "train Loss: 0.4553 Acc: 0.8425\n",
            "valid Loss: 11.6000 Acc: 0.0588\n",
            "\n",
            "Epoch 84/500\n",
            "----------\n",
            "train Loss: 0.4788 Acc: 0.8383\n",
            "valid Loss: 11.4921 Acc: 0.0588\n",
            "\n",
            "Epoch 85/500\n",
            "----------\n",
            "train Loss: 0.4453 Acc: 0.8446\n",
            "valid Loss: 11.4763 Acc: 0.0588\n",
            "\n",
            "Epoch 86/500\n",
            "----------\n",
            "train Loss: 0.4151 Acc: 0.8552\n",
            "valid Loss: 11.5496 Acc: 0.0000\n",
            "\n",
            "Epoch 87/500\n",
            "----------\n",
            "train Loss: 0.6275 Acc: 0.7674\n",
            "valid Loss: 11.7828 Acc: 0.0588\n",
            "\n",
            "Epoch 88/500\n",
            "----------\n",
            "train Loss: 0.4552 Acc: 0.8372\n",
            "valid Loss: 11.4577 Acc: 0.0000\n",
            "\n",
            "Epoch 89/500\n",
            "----------\n",
            "train Loss: 0.4362 Acc: 0.8478\n",
            "valid Loss: 11.7225 Acc: 0.0588\n",
            "\n",
            "Epoch 90/500\n",
            "----------\n",
            "train Loss: 0.4556 Acc: 0.8319\n",
            "valid Loss: 11.8307 Acc: 0.0588\n",
            "\n",
            "Epoch 91/500\n",
            "----------\n",
            "train Loss: 0.4636 Acc: 0.8192\n",
            "valid Loss: 11.8717 Acc: 0.0588\n",
            "\n",
            "Epoch 92/500\n",
            "----------\n",
            "train Loss: 0.4541 Acc: 0.8425\n",
            "valid Loss: 11.8699 Acc: 0.0588\n",
            "\n",
            "Epoch 93/500\n",
            "----------\n",
            "train Loss: 0.3941 Acc: 0.8647\n",
            "valid Loss: 12.0171 Acc: 0.0588\n",
            "\n",
            "Epoch 94/500\n",
            "----------\n",
            "train Loss: 0.4556 Acc: 0.8393\n",
            "valid Loss: 11.6497 Acc: 0.0588\n",
            "\n",
            "Epoch 95/500\n",
            "----------\n",
            "train Loss: 0.4245 Acc: 0.8520\n",
            "valid Loss: 11.7033 Acc: 0.0588\n",
            "\n",
            "Epoch 96/500\n",
            "----------\n",
            "train Loss: 0.4649 Acc: 0.8446\n",
            "valid Loss: 12.1669 Acc: 0.0000\n",
            "\n",
            "Epoch 97/500\n",
            "----------\n",
            "train Loss: 0.4776 Acc: 0.8383\n",
            "valid Loss: 11.7045 Acc: 0.0588\n",
            "\n",
            "Epoch 98/500\n",
            "----------\n",
            "train Loss: 0.4166 Acc: 0.8488\n",
            "valid Loss: 11.5890 Acc: 0.0000\n",
            "\n",
            "Epoch 99/500\n",
            "----------\n",
            "train Loss: 0.3869 Acc: 0.8541\n",
            "valid Loss: 12.0551 Acc: 0.0588\n",
            "\n",
            "Epoch 100/500\n",
            "----------\n",
            "train Loss: 0.4494 Acc: 0.8309\n",
            "valid Loss: 11.5511 Acc: 0.0000\n",
            "\n",
            "Epoch 101/500\n",
            "----------\n",
            "train Loss: 0.3831 Acc: 0.8647\n",
            "valid Loss: 11.6746 Acc: 0.0588\n",
            "\n",
            "Epoch 102/500\n",
            "----------\n",
            "train Loss: 0.4264 Acc: 0.8393\n",
            "valid Loss: 11.5555 Acc: 0.0588\n",
            "\n",
            "Epoch 103/500\n",
            "----------\n",
            "train Loss: 0.4032 Acc: 0.8647\n",
            "valid Loss: 11.4825 Acc: 0.0000\n",
            "\n",
            "Epoch 104/500\n",
            "----------\n",
            "train Loss: 0.4669 Acc: 0.8340\n",
            "valid Loss: 11.6767 Acc: 0.0588\n",
            "\n",
            "Epoch 105/500\n",
            "----------\n",
            "train Loss: 0.4637 Acc: 0.8298\n",
            "valid Loss: 11.4997 Acc: 0.0000\n",
            "\n",
            "Epoch 106/500\n",
            "----------\n",
            "train Loss: 0.4550 Acc: 0.8478\n",
            "valid Loss: 11.6760 Acc: 0.0588\n",
            "\n",
            "Epoch 107/500\n",
            "----------\n",
            "train Loss: 0.3727 Acc: 0.8742\n",
            "valid Loss: 11.8726 Acc: 0.0588\n",
            "\n",
            "Epoch 108/500\n",
            "----------\n",
            "train Loss: 0.5286 Acc: 0.8161\n",
            "valid Loss: 11.5787 Acc: 0.0588\n",
            "\n",
            "Epoch 109/500\n",
            "----------\n",
            "train Loss: 0.4301 Acc: 0.8425\n",
            "valid Loss: 11.4325 Acc: 0.0588\n",
            "\n",
            "Epoch 110/500\n",
            "----------\n",
            "train Loss: 0.4256 Acc: 0.8467\n",
            "valid Loss: 11.6619 Acc: 0.0588\n",
            "\n",
            "Epoch 111/500\n",
            "----------\n",
            "train Loss: 0.4284 Acc: 0.8510\n",
            "valid Loss: 11.3308 Acc: 0.0588\n",
            "\n",
            "Epoch 112/500\n",
            "----------\n",
            "train Loss: 0.4853 Acc: 0.8245\n",
            "valid Loss: 11.7823 Acc: 0.0588\n",
            "\n",
            "Epoch 113/500\n",
            "----------\n",
            "train Loss: 0.4055 Acc: 0.8531\n",
            "valid Loss: 11.6304 Acc: 0.0588\n",
            "\n",
            "Epoch 114/500\n",
            "----------\n",
            "train Loss: 0.3872 Acc: 0.8721\n",
            "valid Loss: 11.9035 Acc: 0.0588\n",
            "\n",
            "Epoch 115/500\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8753\n",
            "valid Loss: 11.6356 Acc: 0.0588\n",
            "\n",
            "Epoch 116/500\n",
            "----------\n",
            "train Loss: 0.4043 Acc: 0.8573\n",
            "valid Loss: 11.4701 Acc: 0.0588\n",
            "\n",
            "Epoch 117/500\n",
            "----------\n",
            "train Loss: 0.3879 Acc: 0.8636\n",
            "valid Loss: 11.4876 Acc: 0.0588\n",
            "\n",
            "Epoch 118/500\n",
            "----------\n",
            "train Loss: 0.4480 Acc: 0.8393\n",
            "valid Loss: 11.6727 Acc: 0.0588\n",
            "\n",
            "Epoch 119/500\n",
            "----------\n",
            "train Loss: 0.4398 Acc: 0.8488\n",
            "valid Loss: 11.3481 Acc: 0.0000\n",
            "\n",
            "Epoch 120/500\n",
            "----------\n",
            "train Loss: 0.4183 Acc: 0.8541\n",
            "valid Loss: 11.7376 Acc: 0.0588\n",
            "\n",
            "Epoch 121/500\n",
            "----------\n",
            "train Loss: 0.4585 Acc: 0.8446\n",
            "valid Loss: 11.8230 Acc: 0.0588\n",
            "\n",
            "Epoch 122/500\n",
            "----------\n",
            "train Loss: 0.4157 Acc: 0.8446\n",
            "valid Loss: 11.5257 Acc: 0.0588\n",
            "\n",
            "Epoch 123/500\n",
            "----------\n",
            "train Loss: 0.4231 Acc: 0.8499\n",
            "valid Loss: 11.7447 Acc: 0.0588\n",
            "\n",
            "Epoch 124/500\n",
            "----------\n",
            "train Loss: 0.3840 Acc: 0.8594\n",
            "valid Loss: 11.4526 Acc: 0.0588\n",
            "\n",
            "Epoch 125/500\n",
            "----------\n",
            "train Loss: 0.4174 Acc: 0.8584\n",
            "valid Loss: 11.4584 Acc: 0.0588\n",
            "\n",
            "Epoch 126/500\n",
            "----------\n",
            "train Loss: 0.4225 Acc: 0.8499\n",
            "valid Loss: 11.7851 Acc: 0.1176\n",
            "\n",
            "Epoch 127/500\n",
            "----------\n",
            "train Loss: 0.3653 Acc: 0.8647\n",
            "valid Loss: 11.7106 Acc: 0.0588\n",
            "\n",
            "Epoch 128/500\n",
            "----------\n",
            "train Loss: 0.3762 Acc: 0.8805\n",
            "valid Loss: 11.8231 Acc: 0.0588\n",
            "\n",
            "Epoch 129/500\n",
            "----------\n",
            "train Loss: 0.4139 Acc: 0.8615\n",
            "valid Loss: 11.6754 Acc: 0.0588\n",
            "\n",
            "Epoch 130/500\n",
            "----------\n",
            "train Loss: 0.4176 Acc: 0.8562\n",
            "valid Loss: 11.8330 Acc: 0.0588\n",
            "\n",
            "Epoch 131/500\n",
            "----------\n",
            "train Loss: 0.4267 Acc: 0.8393\n",
            "valid Loss: 11.7377 Acc: 0.0588\n",
            "\n",
            "Epoch 132/500\n",
            "----------\n",
            "train Loss: 0.4230 Acc: 0.8605\n",
            "valid Loss: 11.9629 Acc: 0.0588\n",
            "\n",
            "Epoch 133/500\n",
            "----------\n",
            "train Loss: 0.3891 Acc: 0.8668\n",
            "valid Loss: 12.1381 Acc: 0.0588\n",
            "\n",
            "Epoch 134/500\n",
            "----------\n",
            "train Loss: 0.4046 Acc: 0.8573\n",
            "valid Loss: 11.7243 Acc: 0.0588\n",
            "\n",
            "Epoch 135/500\n",
            "----------\n",
            "train Loss: 0.3446 Acc: 0.8805\n",
            "valid Loss: 12.0775 Acc: 0.0588\n",
            "\n",
            "Epoch 136/500\n",
            "----------\n",
            "train Loss: 0.3971 Acc: 0.8700\n",
            "valid Loss: 11.7605 Acc: 0.0588\n",
            "\n",
            "Epoch 137/500\n",
            "----------\n",
            "train Loss: 0.4139 Acc: 0.8488\n",
            "valid Loss: 12.2028 Acc: 0.0588\n",
            "\n",
            "Epoch 138/500\n",
            "----------\n",
            "train Loss: 0.3814 Acc: 0.8658\n",
            "valid Loss: 12.3709 Acc: 0.0588\n",
            "\n",
            "Epoch 139/500\n",
            "----------\n",
            "train Loss: 0.3517 Acc: 0.8774\n",
            "valid Loss: 11.9424 Acc: 0.0588\n",
            "\n",
            "Epoch 140/500\n",
            "----------\n",
            "train Loss: 0.4359 Acc: 0.8330\n",
            "valid Loss: 12.0285 Acc: 0.0588\n",
            "\n",
            "Epoch 141/500\n",
            "----------\n",
            "train Loss: 0.3919 Acc: 0.8721\n",
            "valid Loss: 11.9922 Acc: 0.0588\n",
            "\n",
            "Epoch 142/500\n",
            "----------\n",
            "train Loss: 0.3823 Acc: 0.8647\n",
            "valid Loss: 11.9389 Acc: 0.0588\n",
            "\n",
            "Epoch 143/500\n",
            "----------\n",
            "train Loss: 0.4102 Acc: 0.8446\n",
            "valid Loss: 12.1453 Acc: 0.0588\n",
            "\n",
            "Epoch 144/500\n",
            "----------\n",
            "train Loss: 0.3545 Acc: 0.8816\n",
            "valid Loss: 12.1290 Acc: 0.0588\n",
            "\n",
            "Epoch 145/500\n",
            "----------\n",
            "train Loss: 0.4261 Acc: 0.8457\n",
            "valid Loss: 12.9183 Acc: 0.0588\n",
            "\n",
            "Epoch 146/500\n",
            "----------\n",
            "train Loss: 0.3992 Acc: 0.8594\n",
            "valid Loss: 12.7359 Acc: 0.0588\n",
            "\n",
            "Epoch 147/500\n",
            "----------\n",
            "train Loss: 0.3765 Acc: 0.8562\n",
            "valid Loss: 12.9165 Acc: 0.0588\n",
            "\n",
            "Epoch 148/500\n",
            "----------\n",
            "train Loss: 0.4187 Acc: 0.8594\n",
            "valid Loss: 11.9878 Acc: 0.0588\n",
            "\n",
            "Epoch 149/500\n",
            "----------\n",
            "train Loss: 0.4642 Acc: 0.8393\n",
            "valid Loss: 12.3190 Acc: 0.0588\n",
            "\n",
            "Epoch 150/500\n",
            "----------\n",
            "train Loss: 0.3926 Acc: 0.8573\n",
            "valid Loss: 12.2349 Acc: 0.0588\n",
            "\n",
            "Epoch 151/500\n",
            "----------\n",
            "train Loss: 0.3767 Acc: 0.8848\n",
            "valid Loss: 11.8948 Acc: 0.0588\n",
            "\n",
            "Epoch 152/500\n",
            "----------\n",
            "train Loss: 0.4097 Acc: 0.8541\n",
            "valid Loss: 11.9332 Acc: 0.0588\n",
            "\n",
            "Epoch 153/500\n",
            "----------\n",
            "train Loss: 0.3904 Acc: 0.8636\n",
            "valid Loss: 12.2222 Acc: 0.0588\n",
            "\n",
            "Epoch 154/500\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.8742\n",
            "valid Loss: 12.0236 Acc: 0.0588\n",
            "\n",
            "Epoch 155/500\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.8710\n",
            "valid Loss: 11.9778 Acc: 0.1176\n",
            "\n",
            "Epoch 156/500\n",
            "----------\n",
            "train Loss: 0.4783 Acc: 0.8372\n",
            "valid Loss: 12.2717 Acc: 0.0000\n",
            "\n",
            "Epoch 157/500\n",
            "----------\n",
            "train Loss: 0.4301 Acc: 0.8541\n",
            "valid Loss: 11.5725 Acc: 0.0000\n",
            "\n",
            "Epoch 158/500\n",
            "----------\n",
            "train Loss: 0.3669 Acc: 0.8732\n",
            "valid Loss: 11.6773 Acc: 0.0588\n",
            "\n",
            "Epoch 159/500\n",
            "----------\n",
            "train Loss: 0.3943 Acc: 0.8605\n",
            "valid Loss: 11.8820 Acc: 0.0588\n",
            "\n",
            "Epoch 160/500\n",
            "----------\n",
            "train Loss: 0.3697 Acc: 0.8732\n",
            "valid Loss: 11.5150 Acc: 0.0588\n",
            "\n",
            "Epoch 161/500\n",
            "----------\n",
            "train Loss: 0.3952 Acc: 0.8615\n",
            "valid Loss: 11.8806 Acc: 0.0588\n",
            "\n",
            "Epoch 162/500\n",
            "----------\n",
            "train Loss: 0.3563 Acc: 0.8795\n",
            "valid Loss: 11.8252 Acc: 0.0588\n",
            "\n",
            "Epoch 163/500\n",
            "----------\n",
            "train Loss: 0.3690 Acc: 0.8647\n",
            "valid Loss: 11.3501 Acc: 0.0588\n",
            "\n",
            "Epoch 164/500\n",
            "----------\n",
            "train Loss: 0.3915 Acc: 0.8605\n",
            "valid Loss: 11.6023 Acc: 0.0588\n",
            "\n",
            "Epoch 165/500\n",
            "----------\n",
            "train Loss: 0.3483 Acc: 0.8710\n",
            "valid Loss: 12.1052 Acc: 0.0588\n",
            "\n",
            "Epoch 166/500\n",
            "----------\n",
            "train Loss: 0.4087 Acc: 0.8647\n",
            "valid Loss: 11.9156 Acc: 0.0588\n",
            "\n",
            "Epoch 167/500\n",
            "----------\n",
            "train Loss: 0.3903 Acc: 0.8520\n",
            "valid Loss: 11.9382 Acc: 0.0588\n",
            "\n",
            "Epoch 168/500\n",
            "----------\n",
            "train Loss: 0.4289 Acc: 0.8488\n",
            "valid Loss: 11.7979 Acc: 0.0588\n",
            "\n",
            "Epoch 169/500\n",
            "----------\n",
            "train Loss: 0.3867 Acc: 0.8753\n",
            "valid Loss: 11.3849 Acc: 0.0588\n",
            "\n",
            "Epoch 170/500\n",
            "----------\n",
            "train Loss: 0.4001 Acc: 0.8710\n",
            "valid Loss: 11.5935 Acc: 0.0588\n",
            "\n",
            "Epoch 171/500\n",
            "----------\n",
            "train Loss: 0.4262 Acc: 0.8605\n",
            "valid Loss: 11.7314 Acc: 0.0588\n",
            "\n",
            "Epoch 172/500\n",
            "----------\n",
            "train Loss: 0.3887 Acc: 0.8615\n",
            "valid Loss: 11.4205 Acc: 0.0588\n",
            "\n",
            "Epoch 173/500\n",
            "----------\n",
            "train Loss: 0.4240 Acc: 0.8467\n",
            "valid Loss: 11.6087 Acc: 0.0588\n",
            "\n",
            "Epoch 174/500\n",
            "----------\n",
            "train Loss: 0.3760 Acc: 0.8795\n",
            "valid Loss: 11.7131 Acc: 0.0588\n",
            "\n",
            "Epoch 175/500\n",
            "----------\n",
            "train Loss: 0.3719 Acc: 0.8710\n",
            "valid Loss: 11.6744 Acc: 0.0588\n",
            "\n",
            "Epoch 176/500\n",
            "----------\n",
            "train Loss: 0.4369 Acc: 0.8679\n",
            "valid Loss: 11.7921 Acc: 0.0588\n",
            "\n",
            "Epoch 177/500\n",
            "----------\n",
            "train Loss: 0.3606 Acc: 0.8636\n",
            "valid Loss: 11.6761 Acc: 0.0588\n",
            "\n",
            "Epoch 178/500\n",
            "----------\n",
            "train Loss: 0.3458 Acc: 0.8774\n",
            "valid Loss: 12.2948 Acc: 0.0588\n",
            "\n",
            "Epoch 179/500\n",
            "----------\n",
            "train Loss: 0.4462 Acc: 0.8383\n",
            "valid Loss: 11.6805 Acc: 0.0588\n",
            "\n",
            "Epoch 180/500\n",
            "----------\n",
            "train Loss: 0.3667 Acc: 0.8679\n",
            "valid Loss: 11.7362 Acc: 0.0588\n",
            "\n",
            "Epoch 181/500\n",
            "----------\n",
            "train Loss: 0.3863 Acc: 0.8647\n",
            "valid Loss: 11.7969 Acc: 0.0588\n",
            "\n",
            "Epoch 182/500\n",
            "----------\n",
            "train Loss: 0.3533 Acc: 0.8869\n",
            "valid Loss: 11.8522 Acc: 0.0588\n",
            "\n",
            "Epoch 183/500\n",
            "----------\n",
            "train Loss: 0.3516 Acc: 0.8679\n",
            "valid Loss: 11.7412 Acc: 0.0588\n",
            "\n",
            "Epoch 184/500\n",
            "----------\n",
            "train Loss: 0.3588 Acc: 0.8827\n",
            "valid Loss: 11.6308 Acc: 0.0588\n",
            "\n",
            "Epoch 185/500\n",
            "----------\n",
            "train Loss: 0.4026 Acc: 0.8647\n",
            "valid Loss: 11.8042 Acc: 0.0588\n",
            "\n",
            "Epoch 186/500\n",
            "----------\n",
            "train Loss: 0.3410 Acc: 0.8858\n",
            "valid Loss: 11.6726 Acc: 0.0588\n",
            "\n",
            "Epoch 187/500\n",
            "----------\n",
            "train Loss: 0.3999 Acc: 0.8753\n",
            "valid Loss: 11.6228 Acc: 0.0588\n",
            "\n",
            "Epoch 188/500\n",
            "----------\n",
            "train Loss: 0.4153 Acc: 0.8531\n",
            "valid Loss: 11.4164 Acc: 0.0588\n",
            "\n",
            "Epoch 189/500\n",
            "----------\n",
            "train Loss: 0.3922 Acc: 0.8647\n",
            "valid Loss: 11.7976 Acc: 0.0588\n",
            "\n",
            "Epoch 190/500\n",
            "----------\n",
            "train Loss: 0.4182 Acc: 0.8541\n",
            "valid Loss: 11.4995 Acc: 0.0588\n",
            "\n",
            "Epoch 191/500\n",
            "----------\n",
            "train Loss: 0.3998 Acc: 0.8732\n",
            "valid Loss: 11.7621 Acc: 0.0588\n",
            "\n",
            "Epoch 192/500\n",
            "----------\n",
            "train Loss: 0.3507 Acc: 0.8742\n",
            "valid Loss: 11.7738 Acc: 0.0588\n",
            "\n",
            "Epoch 193/500\n",
            "----------\n",
            "train Loss: 0.3651 Acc: 0.8721\n",
            "valid Loss: 11.9689 Acc: 0.0588\n",
            "\n",
            "Epoch 194/500\n",
            "----------\n",
            "train Loss: 0.3880 Acc: 0.8647\n",
            "valid Loss: 11.8240 Acc: 0.0588\n",
            "\n",
            "Epoch 195/500\n",
            "----------\n",
            "train Loss: 0.3946 Acc: 0.8710\n",
            "valid Loss: 11.7742 Acc: 0.0588\n",
            "\n",
            "Epoch 196/500\n",
            "----------\n",
            "train Loss: 0.3862 Acc: 0.8658\n",
            "valid Loss: 11.4682 Acc: 0.0588\n",
            "\n",
            "Epoch 197/500\n",
            "----------\n",
            "train Loss: 0.3817 Acc: 0.8732\n",
            "valid Loss: 11.9822 Acc: 0.0588\n",
            "\n",
            "Epoch 198/500\n",
            "----------\n",
            "train Loss: 0.4059 Acc: 0.8615\n",
            "valid Loss: 11.8240 Acc: 0.0588\n",
            "\n",
            "Epoch 199/500\n",
            "----------\n",
            "train Loss: 0.3974 Acc: 0.8636\n",
            "valid Loss: 11.7734 Acc: 0.0588\n",
            "\n",
            "Epoch 200/500\n",
            "----------\n",
            "train Loss: 0.3469 Acc: 0.8784\n",
            "valid Loss: 11.5837 Acc: 0.0588\n",
            "\n",
            "Epoch 201/500\n",
            "----------\n",
            "train Loss: 0.3848 Acc: 0.8689\n",
            "valid Loss: 11.5530 Acc: 0.0588\n",
            "\n",
            "Epoch 202/500\n",
            "----------\n",
            "train Loss: 0.3843 Acc: 0.8562\n",
            "valid Loss: 12.2718 Acc: 0.0588\n",
            "\n",
            "Epoch 203/500\n",
            "----------\n",
            "train Loss: 0.3948 Acc: 0.8679\n",
            "valid Loss: 11.6802 Acc: 0.0588\n",
            "\n",
            "Epoch 204/500\n",
            "----------\n",
            "train Loss: 0.3849 Acc: 0.8732\n",
            "valid Loss: 11.7126 Acc: 0.0588\n",
            "\n",
            "Epoch 205/500\n",
            "----------\n",
            "train Loss: 0.3913 Acc: 0.8594\n",
            "valid Loss: 12.1661 Acc: 0.0588\n",
            "\n",
            "Epoch 206/500\n",
            "----------\n",
            "train Loss: 0.4109 Acc: 0.8446\n",
            "valid Loss: 12.0333 Acc: 0.0588\n",
            "\n",
            "Epoch 207/500\n",
            "----------\n",
            "train Loss: 0.3928 Acc: 0.8700\n",
            "valid Loss: 11.5847 Acc: 0.0588\n",
            "\n",
            "Epoch 208/500\n",
            "----------\n",
            "train Loss: 0.3472 Acc: 0.8795\n",
            "valid Loss: 11.5957 Acc: 0.0588\n",
            "\n",
            "Epoch 209/500\n",
            "----------\n",
            "train Loss: 0.3645 Acc: 0.8774\n",
            "valid Loss: 11.7606 Acc: 0.0588\n",
            "\n",
            "Epoch 210/500\n",
            "----------\n",
            "train Loss: 0.3437 Acc: 0.8795\n",
            "valid Loss: 11.9507 Acc: 0.0588\n",
            "\n",
            "Epoch 211/500\n",
            "----------\n",
            "train Loss: 0.4172 Acc: 0.8488\n",
            "valid Loss: 11.8243 Acc: 0.0588\n",
            "\n",
            "Epoch 212/500\n",
            "----------\n",
            "train Loss: 0.3978 Acc: 0.8658\n",
            "valid Loss: 11.5038 Acc: 0.0588\n",
            "\n",
            "Epoch 213/500\n",
            "----------\n",
            "train Loss: 0.3849 Acc: 0.8710\n",
            "valid Loss: 11.8587 Acc: 0.0588\n",
            "\n",
            "Epoch 214/500\n",
            "----------\n",
            "train Loss: 0.3514 Acc: 0.8721\n",
            "valid Loss: 11.5552 Acc: 0.0588\n",
            "\n",
            "Epoch 215/500\n",
            "----------\n",
            "train Loss: 0.3700 Acc: 0.8816\n",
            "valid Loss: 11.9984 Acc: 0.0588\n",
            "\n",
            "Epoch 216/500\n",
            "----------\n",
            "train Loss: 0.3823 Acc: 0.8784\n",
            "valid Loss: 11.9457 Acc: 0.0588\n",
            "\n",
            "Epoch 217/500\n",
            "----------\n",
            "train Loss: 0.3331 Acc: 0.8890\n",
            "valid Loss: 12.0330 Acc: 0.0588\n",
            "\n",
            "Epoch 218/500\n",
            "----------\n",
            "train Loss: 0.3897 Acc: 0.8605\n",
            "valid Loss: 11.7662 Acc: 0.0588\n",
            "\n",
            "Epoch 219/500\n",
            "----------\n",
            "train Loss: 0.3842 Acc: 0.8573\n",
            "valid Loss: 11.8732 Acc: 0.0588\n",
            "\n",
            "Epoch 220/500\n",
            "----------\n",
            "train Loss: 0.3668 Acc: 0.8689\n",
            "valid Loss: 11.9790 Acc: 0.0588\n",
            "\n",
            "Epoch 221/500\n",
            "----------\n",
            "train Loss: 0.4119 Acc: 0.8446\n",
            "valid Loss: 12.0029 Acc: 0.0588\n",
            "\n",
            "Epoch 222/500\n",
            "----------\n",
            "train Loss: 0.3804 Acc: 0.8594\n",
            "valid Loss: 11.8504 Acc: 0.0000\n",
            "\n",
            "Epoch 223/500\n",
            "----------\n",
            "train Loss: 0.3775 Acc: 0.8721\n",
            "valid Loss: 11.8913 Acc: 0.0588\n",
            "\n",
            "Epoch 224/500\n",
            "----------\n",
            "train Loss: 0.3953 Acc: 0.8584\n",
            "valid Loss: 11.9741 Acc: 0.0000\n",
            "\n",
            "Epoch 225/500\n",
            "----------\n",
            "train Loss: 0.4445 Acc: 0.8573\n",
            "valid Loss: 11.9349 Acc: 0.0588\n",
            "\n",
            "Epoch 226/500\n",
            "----------\n",
            "train Loss: 0.3317 Acc: 0.8837\n",
            "valid Loss: 12.1980 Acc: 0.0588\n",
            "\n",
            "Epoch 227/500\n",
            "----------\n",
            "train Loss: 0.3539 Acc: 0.8795\n",
            "valid Loss: 12.0996 Acc: 0.0000\n",
            "\n",
            "Epoch 228/500\n",
            "----------\n",
            "train Loss: 0.4000 Acc: 0.8488\n",
            "valid Loss: 11.5408 Acc: 0.0588\n",
            "\n",
            "Epoch 229/500\n",
            "----------\n",
            "train Loss: 0.3593 Acc: 0.8795\n",
            "valid Loss: 11.9334 Acc: 0.0000\n",
            "\n",
            "Epoch 230/500\n",
            "----------\n",
            "train Loss: 0.4303 Acc: 0.8531\n",
            "valid Loss: 12.2462 Acc: 0.0588\n",
            "\n",
            "Epoch 231/500\n",
            "----------\n",
            "train Loss: 0.3559 Acc: 0.8890\n",
            "valid Loss: 12.1014 Acc: 0.0588\n",
            "\n",
            "Epoch 232/500\n",
            "----------\n",
            "train Loss: 0.3447 Acc: 0.8805\n",
            "valid Loss: 12.4689 Acc: 0.0588\n",
            "\n",
            "Epoch 233/500\n",
            "----------\n",
            "train Loss: 0.3489 Acc: 0.8732\n",
            "valid Loss: 12.2748 Acc: 0.0588\n",
            "\n",
            "Epoch 234/500\n",
            "----------\n",
            "train Loss: 0.3970 Acc: 0.8647\n",
            "valid Loss: 11.9130 Acc: 0.0588\n",
            "\n",
            "Epoch 235/500\n",
            "----------\n",
            "train Loss: 0.3728 Acc: 0.8721\n",
            "valid Loss: 11.9225 Acc: 0.0000\n",
            "\n",
            "Epoch 236/500\n",
            "----------\n",
            "train Loss: 0.4163 Acc: 0.8668\n",
            "valid Loss: 12.2868 Acc: 0.0588\n",
            "\n",
            "Epoch 237/500\n",
            "----------\n",
            "train Loss: 0.2905 Acc: 0.9059\n",
            "valid Loss: 12.0778 Acc: 0.0000\n",
            "\n",
            "Epoch 238/500\n",
            "----------\n",
            "train Loss: 0.3736 Acc: 0.8679\n",
            "valid Loss: 12.5731 Acc: 0.0588\n",
            "\n",
            "Epoch 239/500\n",
            "----------\n",
            "train Loss: 0.3760 Acc: 0.8710\n",
            "valid Loss: 12.1673 Acc: 0.0588\n",
            "\n",
            "Epoch 240/500\n",
            "----------\n",
            "train Loss: 0.3782 Acc: 0.8668\n",
            "valid Loss: 11.7779 Acc: 0.0588\n",
            "\n",
            "Epoch 241/500\n",
            "----------\n",
            "train Loss: 0.3929 Acc: 0.8668\n",
            "valid Loss: 11.8426 Acc: 0.0588\n",
            "\n",
            "Epoch 242/500\n",
            "----------\n",
            "train Loss: 0.3948 Acc: 0.8562\n",
            "valid Loss: 11.9212 Acc: 0.0588\n",
            "\n",
            "Epoch 243/500\n",
            "----------\n",
            "train Loss: 0.3710 Acc: 0.8753\n",
            "valid Loss: 11.5980 Acc: 0.0588\n",
            "\n",
            "Epoch 244/500\n",
            "----------\n",
            "train Loss: 0.3738 Acc: 0.8679\n",
            "valid Loss: 11.9911 Acc: 0.0588\n",
            "\n",
            "Epoch 245/500\n",
            "----------\n",
            "train Loss: 0.3371 Acc: 0.8742\n",
            "valid Loss: 12.0438 Acc: 0.0588\n",
            "\n",
            "Epoch 246/500\n",
            "----------\n",
            "train Loss: 0.4217 Acc: 0.8573\n",
            "valid Loss: 12.1419 Acc: 0.0588\n",
            "\n",
            "Epoch 247/500\n",
            "----------\n",
            "train Loss: 0.3820 Acc: 0.8721\n",
            "valid Loss: 12.1840 Acc: 0.0000\n",
            "\n",
            "Epoch 248/500\n",
            "----------\n",
            "train Loss: 0.3653 Acc: 0.8710\n",
            "valid Loss: 11.9756 Acc: 0.0588\n",
            "\n",
            "Epoch 249/500\n",
            "----------\n",
            "train Loss: 0.3626 Acc: 0.8827\n",
            "valid Loss: 12.0325 Acc: 0.0588\n",
            "\n",
            "Epoch 250/500\n",
            "----------\n",
            "train Loss: 0.3431 Acc: 0.8901\n",
            "valid Loss: 11.8750 Acc: 0.0588\n",
            "\n",
            "Epoch 251/500\n",
            "----------\n",
            "train Loss: 0.3998 Acc: 0.8594\n",
            "valid Loss: 12.0846 Acc: 0.0000\n",
            "\n",
            "Epoch 252/500\n",
            "----------\n",
            "train Loss: 0.3461 Acc: 0.8689\n",
            "valid Loss: 11.9814 Acc: 0.0000\n",
            "\n",
            "Epoch 253/500\n",
            "----------\n",
            "train Loss: 0.3890 Acc: 0.8689\n",
            "valid Loss: 12.0168 Acc: 0.0000\n",
            "\n",
            "Epoch 254/500\n",
            "----------\n",
            "train Loss: 0.3456 Acc: 0.8753\n",
            "valid Loss: 12.3131 Acc: 0.0588\n",
            "\n",
            "Epoch 255/500\n",
            "----------\n",
            "train Loss: 0.3357 Acc: 0.8679\n",
            "valid Loss: 11.8836 Acc: 0.0000\n",
            "\n",
            "Epoch 256/500\n",
            "----------\n",
            "train Loss: 0.3777 Acc: 0.8636\n",
            "valid Loss: 11.7651 Acc: 0.0588\n",
            "\n",
            "Epoch 257/500\n",
            "----------\n",
            "train Loss: 0.3866 Acc: 0.8594\n",
            "valid Loss: 11.9497 Acc: 0.0588\n",
            "\n",
            "Epoch 258/500\n",
            "----------\n",
            "train Loss: 0.4038 Acc: 0.8636\n",
            "valid Loss: 11.9707 Acc: 0.0588\n",
            "\n",
            "Epoch 259/500\n",
            "----------\n",
            "train Loss: 0.2950 Acc: 0.9017\n",
            "valid Loss: 11.6070 Acc: 0.0588\n",
            "\n",
            "Epoch 260/500\n",
            "----------\n",
            "train Loss: 0.3759 Acc: 0.8636\n",
            "valid Loss: 11.9026 Acc: 0.0588\n",
            "\n",
            "Epoch 261/500\n",
            "----------\n",
            "train Loss: 0.3655 Acc: 0.8732\n",
            "valid Loss: 12.1376 Acc: 0.0588\n",
            "\n",
            "Epoch 262/500\n",
            "----------\n",
            "train Loss: 0.3366 Acc: 0.8827\n",
            "valid Loss: 11.7278 Acc: 0.0588\n",
            "\n",
            "Epoch 263/500\n",
            "----------\n",
            "train Loss: 0.3920 Acc: 0.8573\n",
            "valid Loss: 12.1599 Acc: 0.0588\n",
            "\n",
            "Epoch 264/500\n",
            "----------\n",
            "train Loss: 0.3891 Acc: 0.8626\n",
            "valid Loss: 11.5881 Acc: 0.0588\n",
            "\n",
            "Epoch 265/500\n",
            "----------\n",
            "train Loss: 0.3147 Acc: 0.8879\n",
            "valid Loss: 11.9410 Acc: 0.0588\n",
            "\n",
            "Epoch 266/500\n",
            "----------\n",
            "train Loss: 0.3713 Acc: 0.8721\n",
            "valid Loss: 11.8323 Acc: 0.0588\n",
            "\n",
            "Epoch 267/500\n",
            "----------\n",
            "train Loss: 0.3916 Acc: 0.8742\n",
            "valid Loss: 12.2658 Acc: 0.0588\n",
            "\n",
            "Epoch 268/500\n",
            "----------\n",
            "train Loss: 0.3839 Acc: 0.8605\n",
            "valid Loss: 12.1698 Acc: 0.0588\n",
            "\n",
            "Epoch 269/500\n",
            "----------\n",
            "train Loss: 0.3746 Acc: 0.8732\n",
            "valid Loss: 11.8931 Acc: 0.0588\n",
            "\n",
            "Epoch 270/500\n",
            "----------\n",
            "train Loss: 0.3447 Acc: 0.8879\n",
            "valid Loss: 12.2435 Acc: 0.0588\n",
            "\n",
            "Epoch 271/500\n",
            "----------\n",
            "train Loss: 0.4083 Acc: 0.8636\n",
            "valid Loss: 12.1308 Acc: 0.0588\n",
            "\n",
            "Epoch 272/500\n",
            "----------\n",
            "train Loss: 0.3322 Acc: 0.8763\n",
            "valid Loss: 11.9656 Acc: 0.0588\n",
            "\n",
            "Epoch 273/500\n",
            "----------\n",
            "train Loss: 0.3959 Acc: 0.8647\n",
            "valid Loss: 11.9288 Acc: 0.0588\n",
            "\n",
            "Epoch 274/500\n",
            "----------\n",
            "train Loss: 0.3743 Acc: 0.8679\n",
            "valid Loss: 12.1926 Acc: 0.0588\n",
            "\n",
            "Epoch 275/500\n",
            "----------\n",
            "train Loss: 0.3234 Acc: 0.8784\n",
            "valid Loss: 12.3937 Acc: 0.0588\n",
            "\n",
            "Epoch 276/500\n",
            "----------\n",
            "train Loss: 0.3425 Acc: 0.8805\n",
            "valid Loss: 12.0568 Acc: 0.0588\n",
            "\n",
            "Epoch 277/500\n",
            "----------\n",
            "train Loss: 0.4248 Acc: 0.8467\n",
            "valid Loss: 11.9480 Acc: 0.0588\n",
            "\n",
            "Epoch 278/500\n",
            "----------\n",
            "train Loss: 0.3471 Acc: 0.8816\n",
            "valid Loss: 12.1690 Acc: 0.0588\n",
            "\n",
            "Epoch 279/500\n",
            "----------\n",
            "train Loss: 0.3283 Acc: 0.8816\n",
            "valid Loss: 11.9385 Acc: 0.0588\n",
            "\n",
            "Epoch 280/500\n",
            "----------\n",
            "train Loss: 0.3567 Acc: 0.8605\n",
            "valid Loss: 12.3636 Acc: 0.0588\n",
            "\n",
            "Epoch 281/500\n",
            "----------\n",
            "train Loss: 0.3388 Acc: 0.8805\n",
            "valid Loss: 12.0253 Acc: 0.0588\n",
            "\n",
            "Epoch 282/500\n",
            "----------\n",
            "train Loss: 0.3471 Acc: 0.8901\n",
            "valid Loss: 11.9947 Acc: 0.0588\n",
            "\n",
            "Epoch 283/500\n",
            "----------\n",
            "train Loss: 0.3099 Acc: 0.8996\n",
            "valid Loss: 12.3302 Acc: 0.0588\n",
            "\n",
            "Epoch 284/500\n",
            "----------\n",
            "train Loss: 0.3877 Acc: 0.8689\n",
            "valid Loss: 12.1504 Acc: 0.0588\n",
            "\n",
            "Epoch 285/500\n",
            "----------\n",
            "train Loss: 0.3941 Acc: 0.8594\n",
            "valid Loss: 11.8807 Acc: 0.0588\n",
            "\n",
            "Epoch 286/500\n",
            "----------\n",
            "train Loss: 0.3395 Acc: 0.8837\n",
            "valid Loss: 12.0846 Acc: 0.0588\n",
            "\n",
            "Epoch 287/500\n",
            "----------\n",
            "train Loss: 0.3598 Acc: 0.8710\n",
            "valid Loss: 12.3580 Acc: 0.0588\n",
            "\n",
            "Epoch 288/500\n",
            "----------\n",
            "train Loss: 0.3680 Acc: 0.8541\n",
            "valid Loss: 12.0050 Acc: 0.0588\n",
            "\n",
            "Epoch 289/500\n",
            "----------\n",
            "train Loss: 0.3477 Acc: 0.8837\n",
            "valid Loss: 12.3616 Acc: 0.0588\n",
            "\n",
            "Epoch 290/500\n",
            "----------\n",
            "train Loss: 0.3876 Acc: 0.8679\n",
            "valid Loss: 12.3620 Acc: 0.0588\n",
            "\n",
            "Epoch 291/500\n",
            "----------\n",
            "train Loss: 0.3796 Acc: 0.8732\n",
            "valid Loss: 12.3937 Acc: 0.0588\n",
            "\n",
            "Epoch 292/500\n",
            "----------\n",
            "train Loss: 0.3505 Acc: 0.8795\n",
            "valid Loss: 12.4995 Acc: 0.0000\n",
            "\n",
            "Epoch 293/500\n",
            "----------\n",
            "train Loss: 0.3575 Acc: 0.8774\n",
            "valid Loss: 12.1409 Acc: 0.0588\n",
            "\n",
            "Epoch 294/500\n",
            "----------\n",
            "train Loss: 0.3753 Acc: 0.8689\n",
            "valid Loss: 12.5942 Acc: 0.0588\n",
            "\n",
            "Epoch 295/500\n",
            "----------\n",
            "train Loss: 0.3548 Acc: 0.8848\n",
            "valid Loss: 12.2768 Acc: 0.0588\n",
            "\n",
            "Epoch 296/500\n",
            "----------\n",
            "train Loss: 0.3937 Acc: 0.8763\n",
            "valid Loss: 12.3611 Acc: 0.0588\n",
            "\n",
            "Epoch 297/500\n",
            "----------\n",
            "train Loss: 0.4076 Acc: 0.8742\n",
            "valid Loss: 12.1824 Acc: 0.0588\n",
            "\n",
            "Epoch 298/500\n",
            "----------\n",
            "train Loss: 0.3622 Acc: 0.8774\n",
            "valid Loss: 12.5898 Acc: 0.0000\n",
            "\n",
            "Epoch 299/500\n",
            "----------\n",
            "train Loss: 0.3809 Acc: 0.8679\n",
            "valid Loss: 12.1801 Acc: 0.0588\n",
            "\n",
            "Epoch 300/500\n",
            "----------\n",
            "train Loss: 0.3892 Acc: 0.8658\n",
            "valid Loss: 12.2830 Acc: 0.0588\n",
            "\n",
            "Epoch 301/500\n",
            "----------\n",
            "train Loss: 0.3324 Acc: 0.8964\n",
            "valid Loss: 12.2446 Acc: 0.0588\n",
            "\n",
            "Epoch 302/500\n",
            "----------\n",
            "train Loss: 0.3583 Acc: 0.8732\n",
            "valid Loss: 12.1515 Acc: 0.0588\n",
            "\n",
            "Epoch 303/500\n",
            "----------\n",
            "train Loss: 0.3248 Acc: 0.8784\n",
            "valid Loss: 11.7172 Acc: 0.0588\n",
            "\n",
            "Epoch 304/500\n",
            "----------\n",
            "train Loss: 0.3559 Acc: 0.8753\n",
            "valid Loss: 12.1520 Acc: 0.1176\n",
            "\n",
            "Epoch 305/500\n",
            "----------\n",
            "train Loss: 0.3636 Acc: 0.8721\n",
            "valid Loss: 11.7485 Acc: 0.0000\n",
            "\n",
            "Epoch 306/500\n",
            "----------\n",
            "train Loss: 0.3411 Acc: 0.8805\n",
            "valid Loss: 11.9458 Acc: 0.0588\n",
            "\n",
            "Epoch 307/500\n",
            "----------\n",
            "train Loss: 0.3918 Acc: 0.8795\n",
            "valid Loss: 11.6538 Acc: 0.0588\n",
            "\n",
            "Epoch 308/500\n",
            "----------\n",
            "train Loss: 0.3648 Acc: 0.8721\n",
            "valid Loss: 11.8275 Acc: 0.0588\n",
            "\n",
            "Epoch 309/500\n",
            "----------\n",
            "train Loss: 0.4012 Acc: 0.8658\n",
            "valid Loss: 12.3951 Acc: 0.0588\n",
            "\n",
            "Epoch 310/500\n",
            "----------\n",
            "train Loss: 0.4026 Acc: 0.8605\n",
            "valid Loss: 12.2362 Acc: 0.0588\n",
            "\n",
            "Epoch 311/500\n",
            "----------\n",
            "train Loss: 0.3406 Acc: 0.8879\n",
            "valid Loss: 12.0796 Acc: 0.0588\n",
            "\n",
            "Epoch 312/500\n",
            "----------\n",
            "train Loss: 0.3235 Acc: 0.8975\n",
            "valid Loss: 12.2139 Acc: 0.0588\n",
            "\n",
            "Epoch 313/500\n",
            "----------\n",
            "train Loss: 0.3771 Acc: 0.8636\n",
            "valid Loss: 12.2338 Acc: 0.0588\n",
            "\n",
            "Epoch 314/500\n",
            "----------\n",
            "train Loss: 0.3487 Acc: 0.8710\n",
            "valid Loss: 12.5575 Acc: 0.0000\n",
            "\n",
            "Epoch 315/500\n",
            "----------\n",
            "train Loss: 0.3446 Acc: 0.8879\n",
            "valid Loss: 11.8749 Acc: 0.0588\n",
            "\n",
            "Epoch 316/500\n",
            "----------\n",
            "train Loss: 0.3046 Acc: 0.8943\n",
            "valid Loss: 12.3120 Acc: 0.0588\n",
            "\n",
            "Epoch 317/500\n",
            "----------\n",
            "train Loss: 0.3712 Acc: 0.8763\n",
            "valid Loss: 12.0493 Acc: 0.0588\n",
            "\n",
            "Epoch 318/500\n",
            "----------\n",
            "train Loss: 0.3002 Acc: 0.8869\n",
            "valid Loss: 11.8843 Acc: 0.0588\n",
            "\n",
            "Epoch 319/500\n",
            "----------\n",
            "train Loss: 0.3658 Acc: 0.8710\n",
            "valid Loss: 12.2232 Acc: 0.0588\n",
            "\n",
            "Epoch 320/500\n",
            "----------\n",
            "train Loss: 0.4103 Acc: 0.8562\n",
            "valid Loss: 11.8364 Acc: 0.0588\n",
            "\n",
            "Epoch 321/500\n",
            "----------\n",
            "train Loss: 0.3975 Acc: 0.8636\n",
            "valid Loss: 11.6711 Acc: 0.0588\n",
            "\n",
            "Epoch 322/500\n",
            "----------\n",
            "train Loss: 0.3976 Acc: 0.8615\n",
            "valid Loss: 12.1291 Acc: 0.0588\n",
            "\n",
            "Epoch 323/500\n",
            "----------\n",
            "train Loss: 0.3644 Acc: 0.8795\n",
            "valid Loss: 12.6117 Acc: 0.0588\n",
            "\n",
            "Epoch 324/500\n",
            "----------\n",
            "train Loss: 0.3497 Acc: 0.8774\n",
            "valid Loss: 12.0563 Acc: 0.0588\n",
            "\n",
            "Epoch 325/500\n",
            "----------\n",
            "train Loss: 0.3134 Acc: 0.8890\n",
            "valid Loss: 12.1620 Acc: 0.0588\n",
            "\n",
            "Epoch 326/500\n",
            "----------\n",
            "train Loss: 0.3400 Acc: 0.8763\n",
            "valid Loss: 12.3158 Acc: 0.0588\n",
            "\n",
            "Epoch 327/500\n",
            "----------\n",
            "train Loss: 0.4170 Acc: 0.8457\n",
            "valid Loss: 12.3355 Acc: 0.0588\n",
            "\n",
            "Epoch 328/500\n",
            "----------\n",
            "train Loss: 0.3903 Acc: 0.8562\n",
            "valid Loss: 12.8085 Acc: 0.0588\n",
            "\n",
            "Epoch 329/500\n",
            "----------\n",
            "train Loss: 0.3213 Acc: 0.8805\n",
            "valid Loss: 12.4983 Acc: 0.0588\n",
            "\n",
            "Epoch 330/500\n",
            "----------\n",
            "train Loss: 0.3758 Acc: 0.8605\n",
            "valid Loss: 12.5859 Acc: 0.0588\n",
            "\n",
            "Epoch 331/500\n",
            "----------\n",
            "train Loss: 0.3141 Acc: 0.8827\n",
            "valid Loss: 12.9080 Acc: 0.0588\n",
            "\n",
            "Epoch 332/500\n",
            "----------\n",
            "train Loss: 0.3168 Acc: 0.9027\n",
            "valid Loss: 12.8794 Acc: 0.0588\n",
            "\n",
            "Epoch 333/500\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.8710\n",
            "valid Loss: 12.8289 Acc: 0.0588\n",
            "\n",
            "Epoch 334/500\n",
            "----------\n",
            "train Loss: 0.2921 Acc: 0.9101\n",
            "valid Loss: 12.5112 Acc: 0.0588\n",
            "\n",
            "Epoch 335/500\n",
            "----------\n",
            "train Loss: 0.3817 Acc: 0.8584\n",
            "valid Loss: 12.5234 Acc: 0.0000\n",
            "\n",
            "Epoch 336/500\n",
            "----------\n",
            "train Loss: 0.2751 Acc: 0.9038\n",
            "valid Loss: 12.2360 Acc: 0.0000\n",
            "\n",
            "Epoch 337/500\n",
            "----------\n",
            "train Loss: 0.3695 Acc: 0.8753\n",
            "valid Loss: 12.6669 Acc: 0.0588\n",
            "\n",
            "Epoch 338/500\n",
            "----------\n",
            "train Loss: 0.4129 Acc: 0.8531\n",
            "valid Loss: 12.4283 Acc: 0.0588\n",
            "\n",
            "Epoch 339/500\n",
            "----------\n",
            "train Loss: 0.2862 Acc: 0.9027\n",
            "valid Loss: 12.3258 Acc: 0.0588\n",
            "\n",
            "Epoch 340/500\n",
            "----------\n",
            "train Loss: 0.3357 Acc: 0.8795\n",
            "valid Loss: 11.8715 Acc: 0.0000\n",
            "\n",
            "Epoch 341/500\n",
            "----------\n",
            "train Loss: 0.3603 Acc: 0.8774\n",
            "valid Loss: 12.2378 Acc: 0.0588\n",
            "\n",
            "Epoch 342/500\n",
            "----------\n",
            "train Loss: 0.3657 Acc: 0.8816\n",
            "valid Loss: 12.2722 Acc: 0.0588\n",
            "\n",
            "Epoch 343/500\n",
            "----------\n",
            "train Loss: 0.3191 Acc: 0.8901\n",
            "valid Loss: 12.6020 Acc: 0.0588\n",
            "\n",
            "Epoch 344/500\n",
            "----------\n",
            "train Loss: 0.3643 Acc: 0.8858\n",
            "valid Loss: 11.9230 Acc: 0.0588\n",
            "\n",
            "Epoch 345/500\n",
            "----------\n",
            "train Loss: 0.3118 Acc: 0.8827\n",
            "valid Loss: 12.2908 Acc: 0.0588\n",
            "\n",
            "Epoch 346/500\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l5RW-Ixkjliv",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "model.eval()\n",
        "\n",
        "accuracy = 0\n",
        "\n",
        "for inputs, labels in dataloaders['valid']:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Class with the highest probability is our predicted class\n",
        "    equality = (labels.data == outputs.max(1)[1])\n",
        "\n",
        "    # Accuracy is number of correct predictions divided by all predictions\n",
        "    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "    \n",
        "print(\"Test accuracy: {:.3f}\".format(accuracy/len(dataloaders['valid'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DX_N0uf_jlmm",
        "colab": {}
      },
      "source": [
        "# Saving the checkpoint\n",
        "model.class_to_idx = image_datasets['train'].class_to_idx\n",
        "checkpoint_name=('cp_densenet_500'+'.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Da_x_lojlq3",
        "colab": {}
      },
      "source": [
        "checkpoint = {'input_size': 1151,\n",
        "              'output_size': 16,\n",
        "              'epochs': epochs,\n",
        "              'batch_size': 64,\n",
        "              'model': models.densenet161(pretrained=True),\n",
        "              'classifier': classifier,\n",
        "              'scheduler': sched,\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'class_to_idx': model.class_to_idx\n",
        "             }\n",
        "   \n",
        "torch.save(checkpoint, checkpoint_name)\n",
        "shutil.copy(checkpoint_name,('gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease/checkpoints'+checkpoint_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KX27swgUjlu-",
        "colab": {}
      },
      "source": [
        "# Loading the checkpoint\n",
        "ckpt = torch.load(checkpoint_name)\n",
        "ckpt.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8qONYRG3lplp",
        "colab": {}
      },
      "source": [
        "# Load a checkpoint and rebuild the model\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.classifier = checkpoint['classifier']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    optimizer = checkpoint['optimizer']\n",
        "    epochs = checkpoint['epochs']\n",
        "    \n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "    return model, checkpoint['class_to_idx']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e7RabGl4lprO",
        "colab": {}
      },
      "source": [
        "model, class_to_idx = load_checkpoint(checkpoint_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F9_HdGLFlpwM",
        "colab": {}
      },
      "source": [
        "idx_to_class = { v : k for k,v in class_to_idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzRYs7lrmE1f"
      },
      "source": [
        "## Inference for Classification\n",
        "### Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "asCFxWf_lp1q",
        "colab": {}
      },
      "source": [
        "image_path = '/content/gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease/valid/14/lm.jpg'\n",
        "img = Image.open(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-3zK4uQ6sB_n",
        "colab": {}
      },
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    # Process a PIL image for use in a PyTorch model\n",
        "    # tensor.numpy().transpose(1, 2, 0)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zgC5YYw1mNLq",
        "colab": {}
      },
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aehqxsmumNR5",
        "colab": {}
      },
      "source": [
        "with Image.open('/content/gdrive/My Drive/Colab Notebooks/Detect_Plant_Disease/valid/14/lm.jpg') as image:\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TxAO8oDamYFY"
      },
      "source": [
        "## Class Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-hQ_QhsomNPl",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z8hdmpb1mbJz",
        "colab": {}
      },
      "source": [
        "model.class_to_idx = image_datasets['train'].class_to_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akLYLOcnmgaJ",
        "colab": {}
      },
      "source": [
        "def predict2(image_path, model, topk=5):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # Implement the code to predict the class from an image file\n",
        "    img = Image.open(image_path)\n",
        "    img = process_image(img)\n",
        "    \n",
        "    # Convert 2D image to 1D vector\n",
        "    img = np.expand_dims(img, 0)\n",
        "    \n",
        "    \n",
        "    img = torch.from_numpy(img)\n",
        "    \n",
        "    model.eval()\n",
        "    inputs = Variable(img).to(device)\n",
        "    logits = model.forward(inputs)\n",
        "    \n",
        "    ps = F.softmax(logits,dim=1)\n",
        "    topk = ps.cpu().topk(topk)\n",
        "    \n",
        "    return (e.data.numpy().squeeze().tolist() for e in topk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MMS4e_rmgso",
        "colab": {}
      },
      "source": [
        "img_path = 'test.jpg'\n",
        "probs, classes = predict2(img_path, model.to(device))\n",
        "print(probs)\n",
        "print(classes)\n",
        "d_n = [fn_to_dn[class_names[e]] for e in classes]\n",
        "print(d_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_rCY1n4mnCr",
        "colab": {}
      },
      "source": [
        "def view_classify(img_path, prob, classes, mapping):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
        "    ax1.set_title(d_n[0])\n",
        "    ax1.imshow(image)\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    y_pos = np.arange(len(prob))\n",
        "    ax2.barh(y_pos, prob, align='center')\n",
        "    ax2.set_yticks(y_pos)\n",
        "    ax2.set_yticklabels(d_n)\n",
        "    \n",
        "    ax2.invert_yaxis()  # labels read top-to-bottom\n",
        "    ax2.set_title('Class Probability')\n",
        "\n",
        "view_classify(img_path, probs, classes, fn_to_dn)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}